# -*- coding: utf-8 -*-
"""abstract_deploy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10JA7JnI8N82GW7AYDpwzD5ZB3psKiaeV
"""


import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
import base64

# Set page config
st.set_page_config(
    page_title="Thesis Abstract Recommendation System",
    page_icon="📚",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .stAlert {
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'recommendations' not in st.session_state:
    st.session_state.recommendations = None

def load_data():
    """Load the required datasets"""
    try:
        # Load scopus data
        scopus_df = pd.read_csv('scopus.csv')
        scopus_filtered = scopus_df[['Author full names', 'Author(s) ID', 'Abstract', 'Author Keywords', 'Index Keywords']]

        # Load FUTA authors data
        futa_authors = pd.read_csv('futa_authors.csv')
        futa_authors = futa_authors.dropna(how='all')

        return scopus_filtered, futa_authors
    except FileNotFoundError as e:
        st.error(f"Required CSV files not found: {e}")
        return None, None



def calculate_similarity(target_abstract, scopus_data):
    """Calculate cosine similarity between target abstract and scopus data"""
    results = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i in range(len(scopus_data)):
        progress = (i + 1) / len(scopus_data)
        progress_bar.progress(progress)
        status_text.text(f'Processing paper {i+1}/{len(scopus_data)}')

        vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)

        # Abstract similarity
        try:
            vector_abs = vectorizer.fit_transform([scopus_data['Abstract'].iloc[i], target_abstract])
            similarity_abs = cosine_similarity(vector_abs)[0][1]
        except:
            similarity_abs = 0

        # Author keywords similarity
        try:
            if pd.notna(scopus_data['Author Keywords'].iloc[i]):
                vector_aut = vectorizer.fit_transform([scopus_data['Author Keywords'].iloc[i], target_abstract])
                similarity_aut = cosine_similarity(vector_aut)[0][1]
            else:
                similarity_aut = np.nan
        except:
            similarity_aut = np.nan

        # Index keywords similarity
        try:
            if pd.notna(scopus_data['Index Keywords'].iloc[i]):
                vector_ind = vectorizer.fit_transform([scopus_data['Index Keywords'].iloc[i], target_abstract])
                similarity_ind = cosine_similarity(vector_ind)[0][1]
            else:
                similarity_ind = np.nan
        except:
            similarity_ind = np.nan

        results.append([
            scopus_data['Author full names'].iloc[i],
            scopus_data['Author(s) ID'].iloc[i],
            similarity_abs,
            similarity_aut,
            similarity_ind
        ])

    progress_bar.empty()
    status_text.empty()

    return pd.DataFrame(results, columns=['Authors', 'IDs', 'Score_Abs', 'Score_Author', 'Score_Index'])

def process_author_ids(results_df, futa_authors):
    """Process author IDs and merge with FUTA authors data"""
    author_scores = []

    for i, row in results_df.iterrows():
        if pd.notna(row['IDs']):
            ids = str(row['IDs']).split(';')
            for author_id in ids:
                try:
                    author_scores.append([float(author_id.strip()), np.round(row['Score_Abs'], 3)])
                except ValueError:
                    continue

    author_scores_df = pd.DataFrame(author_scores, columns=['Auth-ID', 'Score'])

    # Merge with FUTA authors
    merged_df = author_scores_df.merge(futa_authors, how='inner', on='Auth-ID')

    return merged_df.sort_values('Score', ascending=False)

def create_visualizations(recommendations_df):
    """Create visualizations for the recommendations"""

    # Top 20 recommendations bar chart
    top_20 = recommendations_df.head(20)

    fig1 = px.bar(
        top_20,
        x='Score',
        y='Name',
        orientation='h',
        title='Top 20 Recommended Internal Examiners',
        labels={'Score': 'Similarity Score', 'Name': 'Lecturer Name'},
        color='Score',
        color_continuous_scale='viridis'
    )
    fig1.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})

    # Score distribution
    fig2 = px.histogram(
        recommendations_df,
        x='Score',
        nbins=50,
        title='Distribution of Similarity Scores',
        labels={'Score': 'Similarity Score', 'count': 'Number of Lecturers'}
    )

    # Department-wise analysis if department column exists
    fig3 = None
    if 'Department' in recommendations_df.columns:
        dept_stats = recommendations_df.groupby('Department').agg({
            'Score': ['mean', 'count']
        }).round(3)
        dept_stats.columns = ['Average_Score', 'Count']
        dept_stats = dept_stats.reset_index().sort_values('Average_Score', ascending=False)

        fig3 = px.scatter(
            dept_stats,
            x='Count',
            y='Average_Score',
            size='Count',
            hover_data=['Department'],
            title='Department-wise Expertise Analysis',
            labels={'Count': 'Number of Lecturers', 'Average_Score': 'Average Similarity Score'}
        )

    return fig1, fig2, fig3

def main():
    st.markdown('<h1 class="main-header">📚 Thesis Abstract Recommendation System</h1>', unsafe_allow_html=True)

    st.markdown("""
    This system analyzes thesis abstracts and recommends the most suitable internal examiners
    based on similarity with published research works of university lecturers.
    """)

    # Sidebar for input
    st.sidebar.header("Enter Thesis Abstract")

    target_abstract = st.sidebar.text_area(
        "Paste the thesis abstract here:",
        height=300,
        placeholder="Enter or paste the complete thesis abstract that you want to find suitable internal examiners for...",
        help="Enter the full abstract text. The system will analyze this text to find the most suitable internal examiners based on similarity with published research."
    )

    # Main content area
    if target_abstract and target_abstract.strip():
        st.subheader("📋 Target Abstract")
        with st.expander("View Abstract", expanded=False):
            st.write(target_abstract)

        # Add word count and basic validation
        word_count = len(target_abstract.split())
        st.info(f"Abstract contains {word_count} words")

        if word_count < 50:
            st.warning("⚠️ Abstract seems quite short. For better recommendations, consider providing a more detailed abstract.")

        # Load data
        if st.button("🔍 Find Recommendations", type="primary"):
            with st.spinner("Loading datasets..."):
                scopus_data, futa_authors = load_data()

            if scopus_data is not None and futa_authors is not None:
                st.success(f"Loaded {len(scopus_data)} papers and {len(futa_authors)} FUTA authors")

                # Calculate similarities
                with st.spinner("Calculating similarities..."):
                    similarity_results = calculate_similarity(target_abstract, scopus_data)

                # Process results
                with st.spinner("Processing recommendations..."):
                    recommendations = process_author_ids(similarity_results, futa_authors)

                st.session_state.recommendations = recommendations
                st.session_state.processed_data = similarity_results

                st.success("✅ Recommendations generated successfully!")

    elif not target_abstract:
        st.info("👈 Please enter a thesis abstract in the sidebar to get started.")

    else:
        st.warning("Please enter a valid thesis abstract.")

    # Display results
    if st.session_state.recommendations is not None:
        recommendations = st.session_state.recommendations

        # Summary metrics
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Total Matches", len(recommendations))

        with col2:
            st.metric("Avg Similarity", f"{recommendations['Score'].mean():.3f}")

        with col3:
            st.metric("Max Similarity", f"{recommendations['Score'].max():.3f}")

        with col4:
            st.metric("Top 20 Avg", f"{recommendations.head(20)['Score'].mean():.3f}")

        # Tabs for different views
        tab1, tab2, tab3 = st.tabs(["📊 Recommendations", "📈 Analysis", "📋 Raw Data"])

        with tab1:
            st.subheader("Top 20 Recommended Internal Examiners")

            # Display top recommendations
            top_20 = recommendations.head(20)

            # Create a formatted dataframe for display
            display_df = top_20.copy()
            display_df['Rank'] = range(1, len(display_df) + 1)
            display_df['Similarity Score'] = display_df['Score'].apply(lambda x: f"{x:.3f}")

            # Reorder columns
            display_columns = ['Rank', 'Name', 'Similarity Score', 'Auth-ID']
            if 'Department' in display_df.columns:
                display_columns.insert(2, 'Department')

            st.dataframe(
                display_df[display_columns],
                use_container_width=True,
                hide_index=True
            )

            # Download button
            csv = display_df.to_csv(index=False)
            st.download_button(
                label="📥 Download Top 20 Recommendations",
                data=csv,
                file_name="thesis_recommendations.csv",
                mime="text/csv"
            )

        with tab2:
            st.subheader("Similarity Analysis")

            # Create visualizations
            fig1, fig2, fig3 = create_visualizations(recommendations)

            st.plotly_chart(fig1, use_container_width=True)
            st.plotly_chart(fig2, use_container_width=True)

            if fig3:
                st.plotly_chart(fig3, use_container_width=True)

            # Statistics
            st.subheader("📊 Statistical Summary")
            col1, col2 = st.columns(2)

            with col1:
                st.write("**Score Distribution:**")
                st.write(recommendations['Score'].describe())

            with col2:
                if 'Department' in recommendations.columns:
                    st.write("**Top Departments:**")
                    dept_analysis = recommendations.groupby('Department')['Score'].agg(['mean', 'count']).sort_values('mean', ascending=False)
                    st.write(dept_analysis.head(10))

        with tab3:
            st.subheader("Complete Results")
            st.dataframe(recommendations, use_container_width=True)

            # Download full results
            full_csv = recommendations.to_csv(index=False)
            st.download_button(
                label="📥 Download Complete Results",
                data=full_csv,
                file_name="complete_recommendations.csv",
                mime="text/csv"
            )

    # Information section
    with st.expander("ℹ️ How it works"):
        st.markdown("""
        **The Thesis Abstract Recommendation System works as follows:**

        1. **Input Processing**: Enter your thesis abstract in the text area on the left sidebar.

        2. **Similarity Calculation**: Using TF-IDF vectorization and cosine similarity, the system compares your abstract with:
           - Published paper abstracts
           - Author keywords
           - Index keywords

        3. **Recommendation Generation**: The system matches similarity scores with FUTA authors and ranks them by relevance.

        4. **Visualization**: Results are presented through interactive charts and detailed tables.

        **Key Features:**
        - Simple text input interface
        - Multiple similarity metrics
        - Interactive visualizations
        - Downloadable results
        - Department-wise analysis

        **Tips for better results:**
        - Provide a detailed abstract (at least 50 words)
        - Include key technical terms and methodologies
        - Mention the research domain clearly
        """)

    # Footer
    st.markdown("---")
    st.markdown("**Thesis Abstract Recommendation System** - Developed for FUTA Internal Examiner Selection")

if __name__ == "__main__":
    main()

